{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Power Analysis (Brier et al. 2004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "import lascar\n",
    "import numpy as np\n",
    "import plotly.graph_objects as pgo\n",
    "from cwtoolbox import CaptureDevice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = CaptureDevice.create(\"CWLITEXMEGA\")\n",
    "device.compile(file=os.path.abspath(\"../lecture_3/sbox_lookup.c\"))\n",
    "device.flash()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = device.capture(\n",
    "    number_of_traces=500,\n",
    "    input=lambda _: random.randbytes(16)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dict with keys 0,...,8 and values containing\n",
    "# lists of traces where the hamming weight of the first byte equals the key\n",
    "grouped_data_raw = {\n",
    "    hw: [d for d in data if lascar.hamming_weight(d[\"input\"][0]) == hw]\n",
    "    for hw in range(9)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average trace for each group\n",
    "grouped_data = {\n",
    "    hw: np.mean(np.array(traces)[\"trace\"], axis=0)\n",
    "    for hw, traces in grouped_data_raw.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the mean traces\n",
    "fig = pgo.Figure()\n",
    "for hw, trace in grouped_data.items():\n",
    "    fig.add_trace(pgo.Scatter(y=trace, name=f\"HW: {hw}\"))\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot hw vs trace point\n",
    "# The trace point is selected where \"the traces look different\".\n",
    "fig = pgo.Figure()\n",
    "for hw, trace in grouped_data.items():\n",
    "    fig.add_trace(pgo.Scatter(x=[hw], y=[trace[61]]))\n",
    "fig.show()\n",
    "# => We see that the hamming weight of the input is proportional\n",
    "# to the current consumption in the moment where the input is processed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pearson correlation coefficient\n",
    "\n",
    "An interesting statistical formula to face this problem is given by the *Pearson correlation coefficient*. For two random variables $X, Y$ it is defined as\n",
    "\n",
    "$$\\rho_{X,Y} := \\frac{\\mathrm{Cov}(X, Y)}{\\sqrt{\\mathrm{Var}(X)} \\sqrt{\\mathrm{Var}(Y)}} \\ \\in [-1, 1]\\,.$$\n",
    "\n",
    "For two samples of finite length $x = {x_1, ..., x_n}$, $y = {y_1, ..., y_n}$ it can be defined as \n",
    "\n",
    "$$r_{x,y} := \\frac{\\sum_{i=1}^n (x_i - \\bar x)(y_i - \\bar y)}{\\sqrt{\\sum_{i=1}^n (x_i - \\bar x)^2}\\sqrt{\\sum_{i=1}^n (y_i - \\bar y)^2}} \\ \\in [-1, 1]\\,,$$\n",
    "\n",
    "where $\\bar x := \\frac{1}{n} \\sum_{i=1}^n x_i$ is the mean of a sample $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson(xs, ys):\n",
    "    xmean = np.mean(xs)\n",
    "    ymean = np.mean(ys)\n",
    "    return sum((xs - xmean) * (ys - ymean)) / np.sqrt(\n",
    "        sum((xs - xmean) ** 2) * sum((ys - ymean) ** 2)\n",
    "    )\n",
    "\n",
    "\n",
    "fig = pgo.Figure()\n",
    "size = 50\n",
    "data1 = 5 * np.array(range(size)) + np.random.uniform(-size / 4, size / 4, size=size)\n",
    "fig.add_trace(pgo.Scatter(y=data1, name=f\"pearson:{pearson(range(size), data1)}\"))\n",
    "data2 = np.array(range(size)) + np.random.uniform(-size, size, size=size) + 10\n",
    "fig.add_trace(pgo.Scatter(y=data2, name=f\"pearson:{pearson(range(size), data2)}\"))\n",
    "data3 = (\n",
    "    -3 * np.array(range(size)) + np.random.uniform(-size / 4, size / 4, size=size) + 200\n",
    ")\n",
    "fig.add_trace(pgo.Scatter(y=data3, name=f\"pearson:{pearson(range(size), data3)}\"))\n",
    "data4 = 100 * np.sin(np.array(range(size)) / size * np.pi + np.pi) + np.random.uniform(\n",
    "    -size / 10, size / 10, size=size\n",
    ")\n",
    "fig.add_trace(pgo.Scatter(y=data4, name=f\"pearson:{pearson(range(size), data4)}\"))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Attack!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lascar.tools\n",
    "\n",
    "\n",
    "def aes_sbox_cpa(traces, key_byte_index=0, trace_point=145):\n",
    "    # All trace values at the given trace point\n",
    "    values_at_trace_point = traces[\"trace\"][:, trace_point]\n",
    "    # Iterate over all possible keys\n",
    "    pearsons = []\n",
    "    for guess in range(256):\n",
    "        # Hamming weights of hypothesis\n",
    "        hamming_weights = [\n",
    "            lascar.hamming(lascar.tools.aes.sbox[inp[key_byte_index] ^ guess])\n",
    "            for inp in traces[\"input\"]\n",
    "        ]\n",
    "        # Calculate pearson of these two\n",
    "        p = pearson(values_at_trace_point, hamming_weights)\n",
    "        pearsons.append(abs(p))\n",
    "    print(np.argmax(pearsons))\n",
    "\n",
    "\n",
    "aes_sbox_cpa(traces=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rid of the trace point as input\n",
    "def aes_sbox_cpa2(traces, key_byte_index=0):\n",
    "    # Iterate over all possible keys\n",
    "    pearsons = []\n",
    "    for guess in range(256):\n",
    "        # Iterate over all trace points\n",
    "        pearsons_per_point = []\n",
    "        for trace_point in range(traces[\"trace\"].shape[1]):\n",
    "            # All trace values at the given trace point\n",
    "            values_at_trace_point = traces[\"trace\"][:, trace_point]\n",
    "            # Hamming weights of hypothesis\n",
    "            hamming_weights = [\n",
    "                lascar.hamming(lascar.tools.aes.sbox[inp[key_byte_index] ^ guess])\n",
    "                for inp in traces[\"input\"]\n",
    "            ]\n",
    "            # Calculate pearson of these two\n",
    "            p = pearson(values_at_trace_point, hamming_weights)\n",
    "            pearsons_per_point.append(abs(p))\n",
    "        # Store the maximum pearson coefficient of all trace points for the current guess\n",
    "        print(f\"Max pearson for guess {guess}: {max(pearsons_per_point):.02f}\")\n",
    "        pearsons.append(max(pearsons_per_point))\n",
    "    print(np.argmax(pearsons))\n",
    "\n",
    "aes_sbox_cpa2(traces=data[:20], key_byte_index=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 3px solid plum; border-radius: 5px; padding: 5px; width: calc(100% - 20px);\">\n",
    "<div class=\"h2\" style=\"font-variant: all-small-caps;\">Exercise 5</div>\n",
    "\n",
    "Perform a CPA attack using Lascar's `CpaEngine`.\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
